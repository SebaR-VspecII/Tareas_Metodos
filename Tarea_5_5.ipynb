{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gkVPT3fusk-N",
        "outputId": "8b4b7f56-b2a9-4a24-e4f5-0de804f123ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entropía exacta para binomial (n=2000, p=0.7) = 6.404172 bits\n",
            "Entropía aproximada (normal) = 6.404218 bits\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import math\n",
        "\n",
        "# Función que calcula la entropía de Shannon de una distribución Binomial (en bits)\n",
        "def entropia_binomial(n, p):\n",
        "    k = np.arange(n + 1)  # Valores posibles desde 0 hasta n\n",
        "\n",
        "    # Logaritmo del coeficiente binomial usando gamma\n",
        "    logC = np.array([math.lgamma(n + 1) - math.lgamma(i + 1) - math.lgamma(n - i + 1) for i in k])\n",
        "\n",
        "    # Logaritmo de las probabilidades\n",
        "    log_prob = logC + k * math.log(p) + (n - k) * math.log(1 - p)\n",
        "\n",
        "    # Para evitar problemas numéricos, restamos el máximo\n",
        "    max_log = np.max(log_prob)\n",
        "    prob = np.exp(log_prob - max_log)\n",
        "    prob = prob / prob.sum()  # Normalizamos\n",
        "\n",
        "    # Solo consideramos probabilidades positivas\n",
        "    mask = prob > 0\n",
        "    H = -np.sum(prob[mask] * np.log2(prob[mask]))  # Entropía en bits\n",
        "\n",
        "    return H\n",
        "\n",
        "# -----------------------------\n",
        "# Ejemplo de uso\n",
        "\n",
        "p = 0.7       # Probabilidad de éxito\n",
        "n = 2000      # Número de ensayos\n",
        "\n",
        "H_exacta = entropia_binomial(n, p)  # Entropía exacta\n",
        "\n",
        "# Aproximación normal (válida para n grande)\n",
        "H_aprox = 0.5 * math.log2(2 * math.pi * math.e * n * p * (1 - p))\n",
        "\n",
        "print(f\"Entropía exacta para binomial (n={n}, p={p}) = {H_exacta:.6f} bits\")\n",
        "print(f\"Entropía aproximada (normal) = {H_aprox:.6f} bits\")\n"
      ]
    }
  ]
}